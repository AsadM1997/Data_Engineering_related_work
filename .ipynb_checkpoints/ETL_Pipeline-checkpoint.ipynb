{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6263c75e-a258-4fd5-a93c-316fae7df698",
   "metadata": {},
   "source": [
    "1Ô∏è‚É£ What is an ETL Pipeline?\n",
    "An ETL pipeline is a structured process to:\n",
    "\n",
    "Extract ‚Üí Pull data from one or more sources (files, APIs, databases, streams, etc.).\n",
    "\n",
    "Transform ‚Üí Clean, validate, reformat, enrich, or aggregate the data into the required form.\n",
    "\n",
    "Load ‚Üí Push the processed data into a target system (e.g., SQL database, data warehouse, analytics tool).\n",
    "\n",
    "üìå In Data Engineering, ETL is used to move data from raw sources ‚Üí analytics-ready formats.\n",
    "\n",
    "2Ô∏è‚É£ Core Components\n",
    "A. Extract\n",
    "Sources can be:\n",
    "\n",
    "Files ‚Üí CSV, Excel, JSON, Parquet\n",
    "\n",
    "Databases ‚Üí MySQL, PostgreSQL, SQLite\n",
    "\n",
    "APIs ‚Üí REST, GraphQL\n",
    "\n",
    "Streaming ‚Üí Kafka, RabbitMQ\n",
    "\n",
    "Cloud Storage ‚Üí AWS S3, Google Cloud Storage\n",
    "\n",
    "Python tools for extraction:\n",
    "\n",
    "pandas.read_csv() / read_excel() / read_json()\n",
    "\n",
    "requests or httpx for API calls\n",
    "\n",
    "sqlite3 / SQLAlchemy / psycopg2 for DB queries\n",
    "\n",
    "boto3 for AWS S3\n",
    "\n",
    "B. Transform\n",
    "This is often the heaviest part of ETL.\n",
    "Common transformations:\n",
    "\n",
    "Data Cleaning ‚Üí Handle missing values, remove duplicates, fix data types.\n",
    "\n",
    "Data Enrichment ‚Üí Add calculated fields, merge with reference data.\n",
    "\n",
    "Data Aggregation ‚Üí Summaries, grouping, rolling averages.\n",
    "\n",
    "Data Standardization ‚Üí Consistent formats for dates, currencies, casing.\n",
    "\n",
    "Python tools for transformation:\n",
    "\n",
    "pandas ‚Üí For tabular data wrangling.\n",
    "\n",
    "numpy ‚Üí For numeric operations.\n",
    "\n",
    "pyarrow / fastparquet ‚Üí For efficient file formats.\n",
    "\n",
    "Business Logic ‚Üí Applying rules from domain knowledge.\n",
    "\n",
    "C. Load\n",
    "Targets can be:\n",
    "\n",
    "Databases ‚Üí MySQL, PostgreSQL, SQLite\n",
    "\n",
    "Data Warehouses ‚Üí Snowflake, BigQuery, Redshift\n",
    "\n",
    "Data Lakes ‚Üí S3, HDFS\n",
    "\n",
    "Files ‚Üí CSV, Parquet, JSON for reporting\n",
    "\n",
    "Python tools for loading:\n",
    "\n",
    "pandas.to_sql() (with SQLAlchemy engine)\n",
    "\n",
    "Database connectors (mysql-connector-python, psycopg2)\n",
    "\n",
    "boto3 for S3 uploads\n",
    "\n",
    "to_csv() / to_parquet() for local files\n",
    "\n",
    "3Ô∏è‚É£ Simple Example ETL in Python\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "import requests\n",
    "\n",
    "# === 1. EXTRACT ===\n",
    "url = \"https://api.exchangerate-api.com/v4/latest/USD\"\n",
    "data = requests.get(url).json()\n",
    "df = pd.DataFrame(data['rates'].items(), columns=['Currency', 'Rate'])\n",
    "\n",
    "# === 2. TRANSFORM ===\n",
    "df['Rate'] = df['Rate'].round(2)  # Round to 2 decimal places\n",
    "df = df.sort_values(by='Rate', ascending=False)\n",
    "\n",
    "# === 3. LOAD ===\n",
    "conn = sqlite3.connect('exchange_rates.db')\n",
    "df.to_sql('rates', conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "print(\"ETL Pipeline completed successfully!\")\n",
    "4Ô∏è‚É£ Best Practices for ETL Pipelines\n",
    "‚úÖ Make it repeatable ‚Äî wrap in functions or classes.\n",
    "‚úÖ Parameterize ‚Äî avoid hardcoding file paths or credentials.\n",
    "‚úÖ Log everything ‚Äî so you can debug issues.\n",
    "‚úÖ Validate data ‚Äî ensure correct schema & no corruption.\n",
    "‚úÖ Use incremental loads ‚Äî only process new or changed data when possible.\n",
    "‚úÖ Consider orchestration tools ‚Äî Airflow, Prefect, Kedro for production.\n",
    "\n",
    "5Ô∏è‚É£ Scaling Up\n",
    "When your ETL gets bigger:\n",
    "\n",
    "Batch vs. Streaming ETL\n",
    "\n",
    "Batch ‚Üí Runs at fixed intervals (daily/hourly).\n",
    "\n",
    "Streaming ‚Üí Processes data in near real-time (Kafka, Spark Streaming).\n",
    "\n",
    "Distributed Processing ‚Üí Use Spark or Dask for large datasets.\n",
    "\n",
    "Data Quality Checks ‚Üí Great Expectations, dbt tests.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "35e9a137-421b-42c0-b6f5-b08148e9e6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETL Pipeline completed successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import requests\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "# === 1. EXTRACT ===\n",
    "\n",
    "url = \"https://api.exchangerate-api.com/v4/latest/USD\"\n",
    "data =requests.get(url).json()\n",
    "\n",
    "df = pd.DataFrame(data['rates'].items(), columns=['currency', 'rate'])\n",
    "df.head()\n",
    "\n",
    "# === 2. TRANSFORM ===\n",
    "df['rate'] = df['rate'].round(2)\n",
    "df = df.sort_values(by='rate', ascending=False)\n",
    "df.head()\n",
    "\n",
    "# === 3. LOAD ===\n",
    "conn = sqlite3.connect('exchange_rates.db')\n",
    "df.to_sql('rates', conn, if_exists='replace', index=False)\n",
    "conn.close()\n",
    "\n",
    "print(\"ETL Pipeline completed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d488ff-a33b-48e3-ad7e-69f0fec4b5a4",
   "metadata": {},
   "source": [
    "project on employee salary analysis\n",
    "we'll use dataset data.csv in which it  have employee data\n",
    "first connect with mysql then make a database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3fb1b217-61de-4d0a-9660-4f67c4472f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd \n",
    "conn = mysql.connector.connect(\n",
    "      host='127.0.0.1',\n",
    "        port=3306,\n",
    "        user='root',\n",
    "        password='*Notebook@2025',\n",
    "        database='employee'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8adad38d-624e-41eb-91e0-f05f9c654052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30day_sql_query\n",
      "amazon_present_absent\n",
      "basic_sql\n",
      "case_study\n",
      "employee\n",
      "football_matach\n",
      "information_schema\n",
      "invoicing\n",
      "mysql\n",
      "performance_schema\n",
      "sql_hr\n",
      "sql_inventory\n",
      "sql_invoicing\n",
      "sql_store\n",
      "store\n",
      "sys\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SHOW DATABASES\")\n",
    "for db in cursor:\n",
    "    print(db[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ce9da2a1-82a7-4490-a624-902bc19de148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David</td>\n",
       "      <td>34</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>79076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>76699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinn</td>\n",
       "      <td>38</td>\n",
       "      <td>New York</td>\n",
       "      <td>93478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>32</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>92233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul</td>\n",
       "      <td>27</td>\n",
       "      <td>Houston</td>\n",
       "      <td>96396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age       City  Salary\n",
       "0    David   34  San Diego   79076\n",
       "1  Charlie   35    Phoenix   76699\n",
       "2    Quinn   38   New York   93478\n",
       "3      Eve   32    Phoenix   92233\n",
       "4     Paul   27    Houston   96396"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53b34d7-1f5b-4b3c-b9c1-5577aa03aad0",
   "metadata": {},
   "source": [
    "Step 2 ‚Äì Transform: Clean and Analyze in Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "48eacdb6-c349-42a9-a187-e437090e965c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "958d63ea-ade9-4c09-918a-b5ceaf26fdd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinn</td>\n",
       "      <td>38</td>\n",
       "      <td>New York</td>\n",
       "      <td>93478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>32</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>92233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul</td>\n",
       "      <td>27</td>\n",
       "      <td>Houston</td>\n",
       "      <td>96396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grace</td>\n",
       "      <td>47</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>83846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Nate</td>\n",
       "      <td>59</td>\n",
       "      <td>Houston</td>\n",
       "      <td>84534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Name  Age       City  Salary\n",
       "2  Quinn   38   New York   93478\n",
       "3    Eve   32    Phoenix   92233\n",
       "4   Paul   27    Houston   96396\n",
       "7  Grace   47  San Diego   83846\n",
       "8   Nate   59    Houston   84534"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# souppose we want see high erners\n",
    "high_earners = df[df['Salary'] > 80000]\n",
    "high_earners.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "cb3a2974-77ed-47d1-b6de-510bfa24a5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_query= '''CREATE TABLE IF NOT EXISTS emp(\n",
    "Name VARCHAR(100), Age INT, City VARCHAR(100), Salary DECIMAL(10,2)\n",
    ") '''\n",
    "cursor.execute(create_table_query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "66ebbd9d-0c8e-4f55-bb47-6952aeacf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "insert_query=''' INSERT INTO emp(Name, Age, City, Salary) VALUES(%s, %s, %s, %s) '''\n",
    "for _,row in df.iterrows():\n",
    "    cursor.execute(insert_query, tuple(row))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "0ce545d3-5de9-46b9-b96d-2d8d436bec5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Liam', Decimal('118931.00')),\n",
       " ('Paul', Decimal('96396.00')),\n",
       " ('Steve', Decimal('94769.00')),\n",
       " ('Quinn', Decimal('93478.00')),\n",
       " ('Eve', Decimal('92233.00'))]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 5 highest salaries\n",
    "cursor.execute('SELECT Name, Salary FROM emp ORDER BY Salary DESC LIMIT 5')\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "a84d5c9b-13df-44e3-8346-cfbf120b6edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('employee',)\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT DATABASE();\")\n",
    "print(cursor.fetchone())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "87c746bf-d7bc-41f8-a2b6-898b3272a019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT COUNT(*) FROM emp;\")\n",
    "print(cursor.fetchone())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "15a6267c-a842-4ab6-9671-8ba68ccb9bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('David', 34, 'San Diego', Decimal('79076.00'))\n",
      "('Charlie', 35, 'Phoenix', Decimal('76699.00'))\n",
      "('Quinn', 38, 'New York', Decimal('93478.00'))\n",
      "('Eve', 32, 'Phoenix', Decimal('92233.00'))\n",
      "('Paul', 27, 'Houston', Decimal('96396.00'))\n",
      "('Hannah', 58, 'New York', Decimal('59351.00'))\n",
      "('Nate', 29, 'San Antonio', Decimal('60027.00'))\n",
      "('Grace', 47, 'San Diego', Decimal('83846.00'))\n",
      "('Nate', 59, 'Houston', Decimal('84534.00'))\n",
      "('Quinn', 59, 'San Antonio', Decimal('83279.00'))\n",
      "('Grace', 39, 'San Antonio', Decimal('79001.00'))\n",
      "('Ian', 43, 'San Antonio', Decimal('65220.00'))\n",
      "('Bob', 44, 'San Diego', Decimal('48379.00'))\n",
      "('Hannah', 56, 'New York', Decimal('84126.00'))\n",
      "('Paul', 35, 'Houston', Decimal('91438.00'))\n",
      "('Liam', 32, 'Chicago', Decimal('118931.00'))\n",
      "('Hannah', 36, 'Los Angeles', Decimal('80513.00'))\n",
      "('Nate', 29, 'San Antonio', Decimal('89020.00'))\n",
      "('Olivia', 49, 'San Antonio', Decimal('87224.00'))\n",
      "('Steve', 38, 'New York', Decimal('94769.00'))\n"
     ]
    }
   ],
   "source": [
    "cursor.execute(\"SELECT * FROM emp;\")\n",
    "for row in cursor.fetchall():\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "4833570b-7717-4b16-bcca-4ce5830c3b04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>avg_salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>San Diego</td>\n",
       "      <td>70433.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>84466.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New York</td>\n",
       "      <td>82931.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Houston</td>\n",
       "      <td>90789.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>San Antonio</td>\n",
       "      <td>77295.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>118931.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>80513.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          City     avg_salary\n",
       "0    San Diego   70433.666667\n",
       "1      Phoenix   84466.000000\n",
       "2     New York   82931.000000\n",
       "3      Houston   90789.333333\n",
       "4  San Antonio   77295.166667\n",
       "5      Chicago  118931.000000\n",
       "6  Los Angeles   80513.000000"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='pandas only supports SQLAlchemy')\n",
    "query = \"SELECT City, AVG(Salary) AS avg_salary FROM emp GROUP BY City\"\n",
    "\n",
    "df_avg = pd.read_sql(query, conn)\n",
    "\n",
    "df_avg = pd.read_sql(query, conn)\n",
    "df_avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "42b4888e-20d9-4670-8a1e-554ee5f52b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='pandas only supports SQLAlchemy')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT City, AVG(Salary) AS highest_avg_sal\n",
    "FROM emp\n",
    "GROUP BY City\n",
    "ORDER BY highest_avg_sal DESC\n",
    "LIMIT 3;\n",
    "\"\"\"\n",
    "df_avg = pd.read_sql(query, conn)\n",
    "df_avg\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4441ad27-524b-4917-941e-96e6216eec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from urllib.parse import quote_plus \n",
    "\n",
    "# ---- 1. Connection Details ----\n",
    "host = \"127.0.0.1\"\n",
    "port = 3306\n",
    "user = \"root\"\n",
    "password = quote_plus(\"*Notebook@2025\")  # URL-encode special chars\n",
    "database = \"employee\"\n",
    "\n",
    "# SQLAlchemy connection string for MySQL\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}:{port}/{database}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c8932bc9-c6bc-4d34-b9f3-4283ac9de976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [city, avg_salary]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "query = \"SELECT city, AVG(salary) AS avg_salary FROM emp GROUP BY city\"\n",
    "df_avg = pd.read_sql(query, engine)\n",
    "print(df_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "112a00b3-974e-41f2-b38b-d1a9fafef0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import text\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    result = conn.execute(text(\"SELECT * FROM emp\"))\n",
    "    rows = result.fetchall()\n",
    "\n",
    "print(rows)  # see all rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a970b4-87e1-49a6-a3af-2658401b86cf",
   "metadata": {},
   "source": [
    "Extract ‚Äì Get the dataset (CSV or from an API)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6530b81a-da32-4c5d-b9d4-242aec29f169",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David</td>\n",
       "      <td>34</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>79076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>76699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinn</td>\n",
       "      <td>38</td>\n",
       "      <td>New York</td>\n",
       "      <td>93478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>32</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>92233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul</td>\n",
       "      <td>27</td>\n",
       "      <td>Houston</td>\n",
       "      <td>96396</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age       City  Salary\n",
       "0    David   34  San Diego   79076\n",
       "1  Charlie   35    Phoenix   76699\n",
       "2    Quinn   38   New York   93478\n",
       "3      Eve   32    Phoenix   92233\n",
       "4     Paul   27    Houston   96396"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e6ef6c-c471-428e-a537-7f999346700e",
   "metadata": {},
   "source": [
    "Step 2 ‚Äì Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d29c4b8-9aae-4ea3-8d73-a4428e133f97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>City</th>\n",
       "      <th>Salary</th>\n",
       "      <th>yearly_bonus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David</td>\n",
       "      <td>34</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>79076</td>\n",
       "      <td>7907.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Charlie</td>\n",
       "      <td>35</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>76699</td>\n",
       "      <td>7669.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quinn</td>\n",
       "      <td>38</td>\n",
       "      <td>New York</td>\n",
       "      <td>93478</td>\n",
       "      <td>9347.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Eve</td>\n",
       "      <td>32</td>\n",
       "      <td>Phoenix</td>\n",
       "      <td>92233</td>\n",
       "      <td>9223.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Paul</td>\n",
       "      <td>27</td>\n",
       "      <td>Houston</td>\n",
       "      <td>96396</td>\n",
       "      <td>9639.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Name  Age       City  Salary  yearly_bonus\n",
       "0    David   34  San Diego   79076        7907.6\n",
       "1  Charlie   35    Phoenix   76699        7669.9\n",
       "2    Quinn   38   New York   93478        9347.8\n",
       "3      Eve   32    Phoenix   92233        9223.3\n",
       "4     Paul   27    Houston   96396        9639.6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove duplicates\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# Remove rows with missing values in important columns\n",
    "df = df.dropna(subset=['Name', 'Salary'])\n",
    "\n",
    "# Convert salary to integer if not already\n",
    "df['Salary'] = df['Salary'].astype(int)\n",
    "\n",
    "# Add a column for yearly bonus (10% of salary)\n",
    "df['yearly_bonus'] = df['Salary'] * 0.10\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a295d33-a391-4af3-8dc4-ae4a87ca0d37",
   "metadata": {},
   "source": [
    "Step 3 ‚Äì Load into MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f124d0a4-f5d1-4bca-a178-55895b206c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from urllib.parse import quote_plus \n",
    "\n",
    "\n",
    "conn = mysql.connector.connect(\n",
    "      host='127.0.0.1',\n",
    "        port=3306,\n",
    "        user='root',\n",
    "        password='*Notebook@2025',\n",
    "        database='employee'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7014f00a-348a-4b87-90b0-c0d1e32f3cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a table \n",
    "\n",
    "create_table_query = '''CREATE TABLE IF NOT EXISTS employees(\n",
    "            name VARCHAR(255),\n",
    "            age INT,\n",
    "            city VARCHAR(255),\n",
    "            salary INT,\n",
    "            yearly_bonus FLOAT\n",
    ") ''' \n",
    "\n",
    "cursor.execute(create_table_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "06bac335-adad-4cf0-8627-66bb09fd26ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully loaded into MySQL!\n"
     ]
    }
   ],
   "source": [
    "# Insert data into table\n",
    "\n",
    "insert_data_q='''INSERT INTO employees(name, age, city, salary, yearly_bonus)\n",
    "                VALUES(%s, %s, %s, %s, %s )\n",
    "'''\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    cursor.execute(insert_data_q, tuple(row))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "print(\"Data successfully loaded into MySQL!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa5130a-848b-42e2-8026-49c55f964929",
   "metadata": {},
   "source": [
    "etl_pipeline_notebook.py (but all inside your Jupyter cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0536f593-2617-40e9-99ee-c2a2f4f114f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Extracting data...\n",
      "      Name  Age       City  Salary\n",
      "0    David   34  San Diego   79076\n",
      "1  Charlie   35    Phoenix   76699\n",
      "2    Quinn   38   New York   93478\n",
      "3      Eve   32    Phoenix   92233\n",
      "4     Paul   27    Houston   96396\n",
      "üîÑ Transforming data...\n",
      "üíæ Loading data into MySQL...\n",
      "‚úÖ ETL Pipeline complete.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from urllib.parse import quote_plus \n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£ EXTRACT: Load CSV into Pandas DataFrame\n",
    "\n",
    "def extract_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "\n",
    "# 2Ô∏è‚É£ TRANSFORM: Example transformations\n",
    "\n",
    "def transform_data(df):\n",
    "    # Remove duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove rows with missing names\n",
    "    df = df.dropna(subset=['Name','Salary'])\n",
    "\n",
    "    # Example: Ensure salary is numeric\n",
    "    df['salary'] = pd.to_numeric(df['Salary'], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "# 3Ô∏è‚É£ LOAD: Insert into MySQL\n",
    "\n",
    "def load_data(df):\n",
    "\n",
    "\n",
    "    conn = mysql.connector.connect(\n",
    "        host='127.0.0.1',\n",
    "        port=3306,\n",
    "        user='root',\n",
    "        password='*Notebook@2025',\n",
    "        database='employee'\n",
    "    )\n",
    "\n",
    "    cursor = conn.cursor()\n",
    "    # Create table if not exists\n",
    "    cursor.execute(\"\"\"CREATE TABLE IF NOT EXISTS employees(\n",
    "                name VARCHAR(100),\n",
    "                age INT,\n",
    "                city VARCHAR(100),\n",
    "                slaray DECIMAL(10,2),\n",
    "                yearly_bonus DECIMAL(10,2)\n",
    "    ) \"\"\")\n",
    "\n",
    "    # Insert data row-by-row\n",
    "    query=\"\"\"INSERT INTO employees(name,age, city, salary, yearly_bonus) VALUES(%s, %s, %s, %s, %s) \"\"\"\n",
    "    for _,row in df.iterrows():\n",
    "        cursor.execute(query, tuple(row))\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# 4Ô∏è‚É£ RUN the ETL\n",
    "\n",
    "def run_etl(file_path):\n",
    "    print(\"üì• Extracting data...\")\n",
    "    df = extract_data(file_path)\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"üîÑ Transforming data...\")\n",
    "    df = transform_data(df)\n",
    "\n",
    "    print(\"üíæ Loading data into MySQL...\")\n",
    "    load_data(df)\n",
    "    \n",
    "    print(\"‚úÖ ETL Pipeline complete.\")\n",
    "\n",
    "# Example usage in Jupyter\n",
    "run_etl(\"data.csv\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2519563c-15aa-4a1b-af41-db62bceaef1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name', 'Age', 'City', 'Salary', 'yearly_bonus']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80008ecf-8c3b-4686-b23a-47c5a36fb448",
   "metadata": {},
   "source": [
    "\n",
    "# 4Ô∏è‚É£ REPORT: Run analytics and export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9637729-c1b1-4b1d-922f-b7648a79f671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Extracting data...\n",
      "      Name  Age       City  Salary\n",
      "0    David   34  San Diego   79076\n",
      "1  Charlie   35    Phoenix   76699\n",
      "2    Quinn   38   New York   93478\n",
      "3      Eve   32    Phoenix   92233\n",
      "4     Paul   27    Houston   96396\n",
      "üîÑ Transforming data...\n",
      "üíæ Loading data into MySQL...\n",
      "‚úÖ Data loaded into MySQL.\n",
      "üìä Generating reports...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "read_sql() missing 1 required positional argument: 'con'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[32m    100\u001b[39m     export_reports()\n\u001b[32m    102\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ ETL Pipeline complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[43mrun_etl_with_reports\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdata.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m    \n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 100\u001b[39m, in \u001b[36mrun_etl_with_reports\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     97\u001b[39m load_data(df)\n\u001b[32m     99\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müìä Generating reports...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m100\u001b[39m \u001b[43mexport_reports\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ ETL Pipeline complete.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 74\u001b[39m, in \u001b[36mexport_reports\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;66;03m# Example: Average salary per city\u001b[39;00m\n\u001b[32m     70\u001b[39m         query=\u001b[33m\"\"\"\u001b[39m\u001b[33mSELECT city, AVG(Salary) FROM employees \u001b[39m\n\u001b[32m     71\u001b[39m \u001b[33m            GROUP BY City \u001b[39m\n\u001b[32m     72\u001b[39m \u001b[33m            ORDER BY Salary DESC\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[33m        \u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m         report_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mquery\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m         \u001b[38;5;66;03m# Export to CSV\u001b[39;00m\n\u001b[32m     77\u001b[39m         report_df.to_csv(\u001b[33m\"\u001b[39m\u001b[33mAvg_Salary_report.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: read_sql() missing 1 required positional argument: 'con'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from urllib.parse import quote_plus \n",
    "\n",
    "\n",
    "# 1Ô∏è‚É£ EXTRACT: Load CSV into Pandas DataFrame\n",
    "def extract_data(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    return df\n",
    "\n",
    "# 2Ô∏è‚É£ TRANSFORM: Example transformations\n",
    "def transform_data(df):\n",
    "    # Remove duplicate rows\n",
    "    df = df.drop_duplicates()\n",
    "\n",
    "    # Remove rows with missing names\n",
    "    df = df.dropna(subset=['Name','Salary'])\n",
    "\n",
    "    # Example: Ensure salary is numeric\n",
    "    df['Salary'] = pd.to_numeric(df['Salary'], errors='coerce')\n",
    "\n",
    "    return df\n",
    "\n",
    "# 3Ô∏è‚É£ LOAD: Insert into MySQL\n",
    "\n",
    "def load_data(df):\n",
    "\n",
    "\n",
    "    conn = mysql.connector.connect(\n",
    "        host='127.0.0.1',\n",
    "        port=3306,\n",
    "        user='root',\n",
    "        password='*Notebook@2025',\n",
    "        database='employee'\n",
    "    )\n",
    "\n",
    "    cursor = conn.cursor()    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO employees (Name, Age, City, Salary)\n",
    "    VALUES (%s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        cursor.execute(insert_query, (\n",
    "        row['Name'],\n",
    "        row['Age'],\n",
    "        row['City'],\n",
    "        row['Salary']\n",
    "        ))\n",
    "\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"‚úÖ Data loaded into MySQL.\")\n",
    "\n",
    "\n",
    "    \n",
    "def export_reports():\n",
    "        conn = mysql.connector.connect(\n",
    "        host='127.0.0.1',\n",
    "        port=3306,\n",
    "        user='root',\n",
    "        password='*Notebook@2025',\n",
    "        database='employee'\n",
    "        )\n",
    "\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "# Example: Average salary per city\n",
    "        query=\"\"\"SELECT city, AVG(Salary) FROM employees \n",
    "            GROUP BY City \n",
    "            ORDER BY Salary DESC\n",
    "        \"\"\"\n",
    "        report_df = pd.read_sql(\"query\" )\n",
    "        # report_df = pd.read_sql(query, conn)  # ‚úÖ include the connection\n",
    "\n",
    "\n",
    "        # Export to CSV\n",
    "        report_df.to_csv(\"Avg_Salary_report.csv\", index=False)\n",
    "        # Export to Excel\n",
    "        report_df.to_excel(\"Avg_Salary_report.xlsx\", index=False)\n",
    "\n",
    "        conn.commit()\n",
    "        conn.close()\n",
    "        print(\"üìä Reports exported: salary_report.csv & salary_report.xlsx\")\n",
    "\n",
    "# 5Ô∏è‚É£ RUN EVERYTHING\n",
    "\n",
    "\n",
    "def run_etl_with_reports(file_path):\n",
    "    print(\"üì• Extracting data...\")\n",
    "    df = extract_data(file_path)\n",
    "    print(df.head())\n",
    "\n",
    "    print(\"üîÑ Transforming data...\")\n",
    "    df = transform_data(df)\n",
    "\n",
    "    print(\"üíæ Loading data into MySQL...\")\n",
    "    load_data(df)\n",
    "\n",
    "    print(\"üìä Generating reports...\")\n",
    "    export_reports()\n",
    "    \n",
    "    print(\"‚úÖ ETL Pipeline complete.\")\n",
    "\n",
    "run_etl_with_reports(\"data.csv\")    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc10fcd4-dd9c-411f-a291-6ade1ca2892e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
